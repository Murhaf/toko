Metadata-Version: 1.1
Name: toko
Version: 0.1.0
Summary: ML-based Tokenization
Home-page: https://github.com/Murhaf/toko
Author: murhaff
Author-email: murhaff@ifi.uio.no
License: UNKNOWN
Download-URL: https://github.com/Murhaf/toko
Description: toko
        --------
        
        To use (with caution), simply do::
        
            >>> import toko
            >>> toko.wpclassify.wp_classify_file()
            >>> toko.tokenize_sentence()
        
        
        Notes:
        1) Please use absolute paths all the time, especially for Wapiti
        models because the Wapiti path might be different from that of the
        tokenizer.
        
        
        The package runs in three modes: (1) config (2) tokenize and (3)
        train.
        
        ---- config:
        To permanently set the path of Wapiti, you can use:
        python toko config --wapiti /full/path/to/wapiti
        
        After doing this there will be no need to pass the wapiti path with
        the 'tokenize' mode, however if you haven't permanently set the path
        to wapiti you must pass the argument --wapiti. 
        
        ---- tokenize:
        In this mode toko expects a file to tokenize with several optional
        arguments
        
Platform: UNKNOWN
